{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "titanic_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NttzkyIZGSWu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "895e7f00-6078-4107-8734-3c2a747481f1"
      },
      "source": [
        "'''\n",
        "STEP 1: LOAD AND CLEAN THE DATASET\n",
        "dataset comes from: https://www.kaggle.com/c/titanic/data\n",
        "'''\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv('train.csv')\n",
        "\n",
        "#Useful chunks of code for visualizing the dataset\n",
        "#data.head(10)\n",
        "#data.isna().sum()/len(data)\n",
        "#data.dtypes() - all should be of type int or float\n",
        "\n",
        "#droping missing values, redundant variables, and variable Cabin, which had too many missing values\n",
        "data = data[~(data.Age.isna())]\n",
        "data = data[~(data.Embarked.isna())]\n",
        "data.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
        "\n",
        "#encoding categorical variables (ones that had dtype 'object')\n",
        "data['Sex'] = data['Sex'].astype('category').cat.codes\n",
        "data['Embarked'] = data['Embarked'].astype('category').cat.codes\n",
        "\n",
        "y = data.Survived.values\n",
        "X = data.drop('Survived', axis=1).values\n",
        "\n",
        "#spliting into train and test datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, stratify=y)\n",
        "\n",
        "\n",
        "'''\n",
        "STEP 2: TRANSFORM TO TENSORS, LOAD INTO DATASET, AND DECLARE DATALOADERS\n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.float, requires_grad=True)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float, requires_grad=True)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#Loading dataset into PyTorch class\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "#Declaring DataLoaders over training and test dataset\n",
        "train_loader = DataLoader(train_dataset, batch_size=498, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=214, shuffle=False)\n",
        "\n",
        "'''\n",
        "STEP 3: CREATE MODEL CLASS\n",
        "'''\n",
        "class LogisticRegressionModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, output_dim)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out\n",
        "\n",
        "'''\n",
        "STEP 4: DECLARE MODEL CLASS\n",
        "'''\n",
        "input_dim = train_dataset[0][0].shape[0]\n",
        "output_dim = 2\n",
        "\n",
        "model = LogisticRegressionModel(input_dim, output_dim)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "'''\n",
        "STEP 5: DECLARE LOSS, OPTIMIZER AND LEARNING RATE\n",
        "'''\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "'''\n",
        "STEP 6: TRAIN THE MODEL\n",
        "'''\n",
        "\n",
        "num_epochs = 1000\n",
        "iter = 0\n",
        "start = time.time()\n",
        "for epoch in range(num_epochs):\n",
        "    epoch+=1\n",
        "    for i, (x_train, labels) in enumerate(train_loader):\n",
        "        correct_train_predictions = 0\n",
        "        model.train()\n",
        "        x_train = x_train.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(x_train)\n",
        "        \n",
        "        loss = criterion(outputs.squeeze(), labels.squeeze())\n",
        "        \n",
        "\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        correct_train_predictions += (torch.max(outputs,1)[1] == labels).sum()\n",
        "        accuracy_train = 100 * correct_train_predictions / len(train_dataset)\n",
        "        \n",
        "        iter += 1\n",
        "        \n",
        "        if iter % 50 == 0:\n",
        "            correct_test_predictions = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "              model.eval()\n",
        "              for x_test, labels in test_loader:\n",
        "\n",
        "                  x_test = x_test.to(device)\n",
        "                  labels = labels.to(device)\n",
        "\n",
        "                  outputs = model(x_test)\n",
        "                  \n",
        "\n",
        "                  correct_test_predictions += (torch.max(outputs,1)[1] == labels).sum()\n",
        "            \n",
        "            accuracy_test = 100 * correct_test_predictions / len(test_dataset)\n",
        "            \n",
        "            # Print Loss\n",
        "            print('Epoch: {}. Loss: {}. Train Accuracy: {}%, Test Accuracy: {}%'.format(epoch, np.round(loss.item(),6), accuracy_train, accuracy_test))\n",
        "print(f\"Calculations took {time.time() - start}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 50. Loss: 6.71991. Train Accuracy: 35%, Test Accuracy: 41%\n",
            "Epoch: 100. Loss: 4.775579. Train Accuracy: 33%, Test Accuracy: 40%\n",
            "Epoch: 150. Loss: 2.915118. Train Accuracy: 33%, Test Accuracy: 40%\n",
            "Epoch: 200. Loss: 1.298233. Train Accuracy: 41%, Test Accuracy: 41%\n",
            "Epoch: 250. Loss: 0.635334. Train Accuracy: 67%, Test Accuracy: 57%\n",
            "Epoch: 300. Loss: 0.599747. Train Accuracy: 69%, Test Accuracy: 63%\n",
            "Epoch: 350. Loss: 0.577855. Train Accuracy: 69%, Test Accuracy: 63%\n",
            "Epoch: 400. Loss: 0.562135. Train Accuracy: 69%, Test Accuracy: 63%\n",
            "Epoch: 450. Loss: 0.550922. Train Accuracy: 70%, Test Accuracy: 64%\n",
            "Epoch: 500. Loss: 0.542696. Train Accuracy: 71%, Test Accuracy: 64%\n",
            "Epoch: 550. Loss: 0.536314. Train Accuracy: 72%, Test Accuracy: 65%\n",
            "Epoch: 600. Loss: 0.53104. Train Accuracy: 73%, Test Accuracy: 66%\n",
            "Epoch: 650. Loss: 0.526445. Train Accuracy: 73%, Test Accuracy: 68%\n",
            "Epoch: 700. Loss: 0.522288. Train Accuracy: 73%, Test Accuracy: 68%\n",
            "Epoch: 750. Loss: 0.518445. Train Accuracy: 73%, Test Accuracy: 68%\n",
            "Epoch: 800. Loss: 0.514851. Train Accuracy: 74%, Test Accuracy: 68%\n",
            "Epoch: 850. Loss: 0.51147. Train Accuracy: 74%, Test Accuracy: 68%\n",
            "Epoch: 900. Loss: 0.508284. Train Accuracy: 74%, Test Accuracy: 68%\n",
            "Epoch: 950. Loss: 0.50528. Train Accuracy: 75%, Test Accuracy: 68%\n",
            "Epoch: 1000. Loss: 0.502449. Train Accuracy: 75%, Test Accuracy: 69%\n",
            "Calculations took 14.585177183151245\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngMwTVIaGXpn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0a0b3452-f6c7-4e5c-b33c-d2bd64748346"
      },
      "source": [
        "# Comparison with sklearn's LinearRegression implementation \n",
        "# (detach method on X_train, and X_test is nessecary to remove track of gradients from tensors inside them)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(max_iter=1000, solver='lbfgs')\n",
        "model.fit(X_train.detach(), y_train)\n",
        "model.score(X_train.detach(), y_train), model.score(X_test.detach(),y_test)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8172690763052208, 0.8037383177570093)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    }
  ]
}
